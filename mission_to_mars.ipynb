{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymongo\n",
    "import tweepy\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/Users/victo/ChromeDriver/chromedriver.exe') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step one is to visit the NASA Mars News Site to scrape the title/and paragraph text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"NASA's InSight Passes Halfway to Mars, Instruments Check In\", \"NASA's InSight spacecraft, en route to a Nov. 26 landing on Mars, passed the halfway mark on Aug. 6. All of its instruments have been tested and are working well.\"]\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('C:/Users/victo/ChromeDriver/chromedriver.exe') \n",
    "mars_news = 'https://mars.nasa.gov/news/'\n",
    "driver.get(mars_news)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "news_title = soup.find(\"div\", class_ = \"content_title\").text\n",
    "news_content = soup.find(\"div\", class_ = \"article_teaser_body\").text\n",
    "news = [news_title, news_content]\n",
    "print(news)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 is to visit JPL site and find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars/spaceimages/images/mediumsize/PIA16021_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('C:/Users/victo/ChromeDriver/chromedriver.exe') \n",
    "mars_image = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "driver.get(mars_image)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "images = soup.find(\"a\", class_ = \"button fancybox\")\n",
    "featured_image_url = mars_image + images.get('data-fancybox-href')\n",
    "print(featured_image_url)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we gotta visit the official NASA Mars twitter account to scrape the latest weather tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Sol 2144 (2018-08-18), high -11C/12F, low -67C/-88F, pressure at 8.67 hPa, daylight 05:29-17:42'\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('C:/Users/victo/ChromeDriver/chromedriver.exe') \n",
    "twitter_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "html = driver.page_source\n",
    "response = requests.get(twitter_url)\n",
    "soup = BeautifulSoup(response.text,\"lxml\")\n",
    "tweets = soup.findAll('li',{\"class\":'js-stream-item'})\n",
    "tweet_records = []\n",
    "for tweet in tweets:\n",
    "        if tweet.find('p',{\"class\":'tweet-text'}):\n",
    "            tweet_text = tweet.find('p',{\"class\":'tweet-text'}).text.encode('utf8').strip()\n",
    "        tweet_records.append(tweet_text)\n",
    "mars_weather_status = tweet_records[1]\n",
    "print(mars_weather_status)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have almost all the data that we want, at this point we are going to scrape the table containing facts about the planet including Diameter, Mass, etc from the mars facts page, let's also go ahead and use pandas' to html method to put the scraped facts into an html string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <thead>\n",
      "    <tr style=\"text-align: right;\">\n",
      "      <th></th>\n",
      "      <th>Value</th>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Description</th>\n",
      "      <th></th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <th>Equatorial Diameter:</th>\n",
      "      <td>6,792 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Polar Diameter:</th>\n",
      "      <td>6,752 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Mass:</th>\n",
      "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Moons:</th>\n",
      "      <td>2 (Phobos &amp; Deimos)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Orbit Distance:</th>\n",
      "      <td>227,943,824 km (1.52 AU)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Orbit Period:</th>\n",
      "      <td>687 days (1.9 years)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Surface Temperature:</th>\n",
      "      <td>-153 to 20 Â°C</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>First Record:</th>\n",
      "      <td>2nd millennium BC</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Recorded By:</th>\n",
      "      <td>Egyptian astronomers</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('C:/Users/victo/ChromeDriver/chromedriver.exe') \n",
    "facts = requests.get(\"https://space-facts.com/mars/\")\n",
    "soup = BeautifulSoup(facts.content, 'lxml')\n",
    "mars_table = soup.find_all('table')[0]\n",
    "mars_data = pd.read_html(str(mars_table))[0]\n",
    "mars_data.columns = [\"Description\", \"Value\"]\n",
    "mars_data = mars_data.set_index(\"Description\")\n",
    "mars_facts = mars_data.to_html(index = True, header =True)\n",
    "print(mars_facts)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last thing we are going to do is to scrape some high resolution images for each of Mar's hemispheres from the USGS Astrogeology page. I am going to save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name and I am going use a Python dictionary to store the data using the keys img_url and title. Lastly, I am going to append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('C:/Users/victo/ChromeDriver/chromedriver.exe') \n",
    "hemisphere_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "driver.get(hemisphere_url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "mars_hemisphere_list = []\n",
    "\n",
    "products = soup.find(\"div\", class_ = \"result-list\" )\n",
    "hemispheres = products.find_all(\"div\", class_=\"item\")\n",
    "\n",
    "for hemisphere in hemispheres:\n",
    "        title = hemisphere.find(\"h3\").text\n",
    "        title = title.replace(\"Enhanced\", \"\")\n",
    "        end_link = hemisphere.find(\"a\")[\"href\"]\n",
    "        image_url = \"https://astrogeology.usgs.gov/\" + end_link\n",
    "        mars_hemisphere_list.append({\"title\": title, \"img_url\": image_url})\n",
    "def get_high_res_url(some_url):\n",
    "        response = requests.get(some_url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        links = soup.find_all(\"a\")\n",
    "        tifs = [j for j in links if \".tif\" in j.attrs.get('href')]\n",
    "        return tifs[0].get('href')\n",
    "\n",
    "updated_photos = []\n",
    "\n",
    "for data in mars_hemisphere_list:\n",
    "        link_to_check = data.get('img_url')\n",
    "        title = data.get('title')\n",
    "        final_image_url = get_high_res_url(link_to_check)\n",
    "        updated_photos.append({\n",
    "            'Title': title,\n",
    "            'Url': final_image_url\n",
    "        })\n",
    "\n",
    "print(final_image_url)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
